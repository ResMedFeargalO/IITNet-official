{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sklearn.metrics as skmet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *\n",
    "from models.main_models import *\n",
    "from loader import EEGDataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "class OneFoldTrainer:\n",
    "    def __init__(self, args, fold, config):\n",
    "        self.args = args\n",
    "        self.fold = fold\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print('[INFO] Config name: {}'.format(os.path.basename(args.config)))\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.ckpt_path = os.path.join('checkpoints', self.config['config_name'])\n",
    "        self.ckpt_name = 'ckpt_fold-{0:02d}.pth'.format(self.fold)\n",
    "        self.early_stopping = EarlyStopping(patience=config['patience'], verbose=True, ckpt_path=self.ckpt_path, ckpt_name=self.ckpt_name, mode=self.config['early_stopping_mode'])\n",
    "        \n",
    "        self.dataset_args = {'config': self.config, 'fold': self.fold}\n",
    "        self.dataloader_args = {'batch_size': self.config['batch_size'], 'num_workers': 4*len(self.args.gpu.split(\",\"))}\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        self.loader_dict = self.build_dataloader()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "        \n",
    "    def build_model(self):\n",
    "        model = MainModel(self.config)\n",
    "        print('[INFO] Number of params of model: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "        model = torch.nn.DataParallel(model, device_ids=list(range(len(self.args.gpu.split(\",\")))))\n",
    "        model.to(self.device)\n",
    "        print('[INFO] Model prepared, Device used: {}, GPU:{}'.format(self.device, self.args.gpu))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def build_dataloader(self):\n",
    "        train_dataset = EEGDataLoader(mode='train', **self.dataset_args)\n",
    "        train_loader = DataLoader(dataset=train_dataset, shuffle=True, **self.dataloader_args)\n",
    "        val_dataset = EEGDataLoader(mode='val', **self.dataset_args)\n",
    "        val_loader = DataLoader(dataset=val_dataset, shuffle=True, **self.dataloader_args)\n",
    "        test_dataset = EEGDataLoader(mode='test', **self.dataset_args)\n",
    "        test_loader = DataLoader(dataset=test_dataset, shuffle=True, **self.dataloader_args)\n",
    "        print('[INFO] Dataloader prepared')\n",
    "\n",
    "        return {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "    \n",
    "    def train_one_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        correct, total, train_loss = 0, 0, 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(self.loader_dict['train']):\n",
    "            total += labels.size(0)\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.view(-1).to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            progress_bar(i, len(self.loader_dict['train']), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                    % (train_loss / (i + 1), 100. * correct / total, correct, total))\n",
    "            \n",
    "        writer.add_scalar('Accuracy/Train', 100. * correct / total, epoch)\n",
    "        writer.add_scalar('Loss/Train', train_loss / (i + 1), epoch)\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, mode, epoch=0):\n",
    "        self.model.eval()\n",
    "        correct, total, eval_loss = 0, 0, 0\n",
    "        y_true = np.zeros(0)\n",
    "        y_pred = np.zeros((0, self.config['num_classes']))\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(self.loader_dict[mode]):\n",
    "            total += labels.size(0)\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.view(-1).to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            y_true = np.concatenate([y_true, labels.cpu().numpy()])\n",
    "            y_pred = np.concatenate([y_pred, outputs.cpu().numpy()])\n",
    "\n",
    "            progress_bar(i, len(self.loader_dict[mode]), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                    % (eval_loss / (i + 1), 100. * correct / total, correct, total))\n",
    "            \n",
    "\n",
    "\n",
    "        if mode == 'val':\n",
    "            writer.add_scalar('Accuracy/Val', 100. * correct / total, epoch)\n",
    "            writer.add_scalar('Loss/Val', eval_loss / (i + 1), epoch)\n",
    "            return 100. * correct / total, eval_loss\n",
    "        elif mode == 'test':\n",
    "            return y_true, y_pred\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def run(self):\n",
    "        if not self.args.test_only:\n",
    "            for epoch in range(self.config['max_epochs']):\n",
    "                print('\\n[INFO] Fold: {}, Epoch: {}'.format(self.fold, epoch))\n",
    "                self.train_one_epoch(epoch)\n",
    "                val_acc, val_loss = self.evaluate(mode='val', epoch=epoch)\n",
    "                self.early_stopping(val_acc, val_loss, self.model)\n",
    "                if self.early_stopping.early_stop:\n",
    "                    break\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.ckpt_path, self.ckpt_name)))\n",
    "        y_true, y_pred = self.evaluate(mode='test')\n",
    "        print('')\n",
    "\n",
    "        return y_true, y_pred\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--seed', type=int, default=42, help='random seed')\n",
    "    parser.add_argument('--gpu', type=str, default=\"0\", help='gpu id(s)')\n",
    "    parser.add_argument('--config', type=str, default=\"IITNetV2\", help='.json')\n",
    "    parser.add_argument('--test-only', action='store_true', help='if true, only evaluation is conducted')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "\n",
    "    # For reproducibility\n",
    "    set_random_seed(args.seed, use_cuda=True)\n",
    "\n",
    "    with open(args.config) as config_file:\n",
    "        config = json.load(config_file)\n",
    "    config['config_name'] = os.path.basename(args.config).replace('.json', '')\n",
    "\n",
    "    Y_true = np.zeros(0)\n",
    "    Y_pred = np.zeros((0, config['num_classes']))\n",
    "\n",
    "    #for fold in range(1, config['n_splits'] + 1):\n",
    "    # fold=1\n",
    "    # trainer = OneFoldTrainer(args, fold, config)\n",
    "    # y_true, y_pred = trainer.run()\n",
    "    # Y_true = np.concatenate([Y_true, y_true])\n",
    "    # Y_pred = np.concatenate([Y_pred, y_pred])\n",
    "\n",
    "    # summarize_result(config, fold, Y_true, Y_pred)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m OneFoldTrainer(\u001b[43margs\u001b[49m, fold, config)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = OneFoldTrainer(args, fold, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
